# üìö Projeto RAG com Re-Rank: An√°lise de "Os Sert√µes"

Este projeto implementa uma arquitetura RAG (Retrieval-Augmented Generation) com reranqueamento (reranking) para responder a perguntas espec√≠ficas sobre o livro _"Os Sert√µes"_ de Euclides da Cunha.

Utilizamos um modelo LLM (ChatGPT), embeddings da OpenAI, uma base vetorial (ChromaDB) e um reranker da Cohere para otimizar a busca de trechos relevantes antes de gerar a resposta final.

---

## üß† O que √© Rerank RAG?

- O Rerank RAG √© uma evolu√ß√£o do RAG cl√°ssico.
- No RAG tradicional:
  Ap√≥s buscar os documentos mais relevantes (top K), todos s√£o usados diretamente para gerar a resposta.

- No Rerank RAG:
  Ap√≥s buscar os documentos (top K), um reranker (modelo de aprendizado) reorganiza ou filtra os documentos.
  Somente os melhores (mais relevantes para a pergunta) s√£o enviados para o LLM.

- Benef√≠cios do Rerank RAG:
  Reduz o ru√≠do no contexto.
  Melhora a qualidade e a precis√£o da resposta.
  Usa menos tokens (mais barato e r√°pido).

- No projeto:
  Recuperamos 10 documentos.
  O reranker da Cohere seleciona os 3 mais relevantes.
  O ChatGPT gera a resposta com base apenas nesses 3.

## üîß Como funciona o projeto

1. **Carregamento de ambiente:**  
   As vari√°veis de ambiente s√£o carregadas usando `dotenv`.

2. **Carregamento do documento:**  
   O PDF de _"Os Sert√µes"_ √© carregado e dividido em pequenas partes (chunks) de at√© 4000 caracteres.

3. **Indexa√ß√£o vetorial:**  
   Os chunks s√£o embutidos usando o modelo `text-embedding-3-small` da OpenAI e armazenados em uma base vetorial (`ChromaDB`).

4. **Configura√ß√£o do retriever inicial:**  
   O retriever inicial (`naive_retriever`) busca os 10 chunks mais semelhantes ao texto da pergunta.

5. **Re-Ranking com Contextual Compression:**  
   Em vez de usar todos os 10 resultados, o projeto utiliza um reranker (`CohereRerank`) que:

   - **Reavalia** os 10 chunks recuperados,
   - **Seleciona** apenas os 3 mais relevantes.

   Isso √© feito com a classe `ContextualCompressionRetriever`, que comprime o contexto retornado, aumentando a precis√£o da resposta.

6. **Gera√ß√£o de resposta:**  
   Um prompt espec√≠fico √© montado com o contexto selecionado e a pergunta.  
   O ChatGPT (gpt-3.5-turbo) gera a resposta com at√© 500 tokens.

7. **Execu√ß√£o:**  
   As perguntas listadas no c√≥digo s√£o respondidas automaticamente e impressas no console.

---

## üöÄ Como rodar o projeto

1. Clone o reposit√≥rio.
2. Instale as depend√™ncias necess√°rias:
   ```bash
   pip install langchain langchain-openai langchain-cohere langchain-community chromadb python-dotenv
   ```
